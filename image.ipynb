{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1Q5eLWlyxdyWPEVvqN-lzkK8IKLlxFi7X",
      "authorship_tag": "ABX9TyMw3aGCuQDXF1EZ9oQNg2fF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/By0ungJoo/dacon/blob/main/image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import shutil # high-level file operations\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import re\n",
        "import cv2\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform"
      ],
      "metadata": {
        "id": "CQ55w08oudxF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "## 주어진 train_df에 각 레이블마다 원-핫인코딩값을 생성할 인덱스 부여\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/DACON_이상치 탐지 알고리즘 경진대회/open/train_df.csv')\n",
        "final_train88_df = train_df.copy()\n",
        "label_lst = final_train88_df.label.unique().tolist()\n",
        "label_lst.sort()\n",
        "one_hot_label = pd.DataFrame(label_lst, columns = {'label'})\n",
        "one_hot_label['one_hot_label'] = one_hot_label.index.tolist()\n",
        "one_hot_label\n",
        "\n",
        "final_train88_df = pd.merge(final_train88_df, one_hot_label, how = 'left', on = 'label')\n",
        "final_train88_df\n",
        "\n",
        "# 학습 파일 기본 경로 지정 및 넘파이 배열로 변환\n",
        "# 넘파일 배열을 생성할 레이블의 one_hot_label값 [0 ~ 87] / df > one_hot_label 참조\n",
        "image_dir = '/content/drive/MyDrive/dacon/dacon/open/train'\n",
        "num_total_label = 88 # 레이블 총 개수\n",
        "one_hot_label = [x for x in range(88)]\n",
        "\n",
        "img_rows = 224\n",
        "img_cols = 224\n",
        "\n",
        "X = [] # 입력 데이터\n",
        "Y = [] # 정답값\n",
        "\n",
        "## 이미지 배열 파일 생성\n",
        "for index, row in tqdm(final_train88_df.iterrows(), total = len(final_train88_df)) : \n",
        "  filename = row['file_name']\n",
        "  label_idx = row['one_hot_label']\n",
        "  # img_label : Y 배열에 들어갈 원-핫 인코딩된 정답값\n",
        "  img_label = [0 for i in range(num_total_label)]\n",
        "  img_label[label_idx] = 1\n",
        "\n",
        "  img = cv2.imread(f'{image_dir}/{filename}').astype('float32')\n",
        "  img = cv2.resize(img, (img_rows,img_cols))#, fx=img_w/img.shape[1], fy=img_h/img.shape[0])\n",
        "  X.append(img/256)\n",
        "  Y.append(img_label)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.3, random_state=1234)\n",
        "\n",
        "## 안쓰는 변수 비우기 : 램관리\n",
        "del X, Y\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeK3x-wOrPCK",
        "outputId": "d05c6516-86ae-4bc8-c58c-fa640eaa882e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:16<00:00, 31.34it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bottleneck_residual_block(X, f, filters, stage, block, reduce=False, s=2):\n",
        "    \"\"\"    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, height, width, channels)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    reduce -- boolean, True = identifies the reduction layer at the beginning of each learning stage\n",
        "    s -- integer, strides\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (H, W, C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    if reduce:\n",
        "        # if we are to reduce the spatial size, apply a 1x1 CONV layer to the shortcut path\n",
        "        # to do that, we need both CONV layers to have similar strides \n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "        X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "        X = Activation('relu')(X)\n",
        "        \n",
        "        X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "        X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "    else: \n",
        "        # First component of main path\n",
        "        X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "        X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "        X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "NfwzObjs_J89"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape, classes):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape -- tuple shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='a', reduce=True, s=1)\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 \n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='e')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='f')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='g')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='h')\n",
        "    X = bottleneck_residual_block(X, 3, [128, 128, 512], stage=3, block='i')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='g')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='h')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='i')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='j')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='k')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='l')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='m')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='n')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='o')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='p')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='q')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='r')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='s')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='t')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='u')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='v')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='w')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='x')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='y')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='z')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='aa')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ab')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ac')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ad')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ae')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='af')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ag')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ah')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ai')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='aj')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='ak')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='al')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='am')\n",
        "    X = bottleneck_residual_block(X, 3, [256, 256, 1024], stage=4, block='an')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='a', reduce=True, s=2)\n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = bottleneck_residual_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL \n",
        "    X = AveragePooling2D((1,1), name=\"avg_pool\")(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create the model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rn5OUSFe_NLu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (224, 224, 3), classes = 88)"
      ],
      "metadata": {
        "id": "2v_Riaxr_REK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "F25AQKOysd2t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/dacon/dacon/model1.h5', monitor='loss', save_best_only=True)\n",
        "# patience 5\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "VMthUMvxsglM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks =[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4DCwioxsgiT",
        "outputId": "43330b32-78ea-4359-b9b7-a456fcddcc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/47 [===========>..................] - ETA: 6:44 - loss: 26.1260 - accuracy: 0.1242"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 학습 과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## 그래프 : loss , val_loss\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "## loss 그래프\n",
        "loss_ax.plot(history.history['loss'],'y',label='train_loss') # 노란색\n",
        "loss_ax.plot(history.history['val_loss'],color='red' ,label='val_loss') # 빨간색\n",
        "\n",
        "## accuracy 그래프\n",
        "acc_ax.plot(history.history['accuracy'],'g',label='train_accuracy') # 초록색\n",
        "acc_ax.plot(history.history['val_accuracy'],'b',label='val_accuracy') # 파란색\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3bf3-Iixsgdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch 100 으로 코드 돌리기 "
      ],
      "metadata": {
        "id": "5VF5pQaz97-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}